{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b618576-1eec-48b3-a2c8-39d676301eb2",
   "metadata": {},
   "source": [
    "1. https://machinelearningmastery.com/how-to-implement-scaled-dot-product-attention-from-scratch-in-tensorflow-and-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32869462-d7e6-4f3e-9ea3-1bece36d86ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 5, 7, 9, 5, 3)\n",
      "(9, 5, 7, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones([9, 5, 7, 4])\n",
    "c = np.ones([9, 5, 4, 3])\n",
    "print(np.dot(a, c).shape)\n",
    "print(np.matmul(a, c).shape)\n",
    "# print(np.dot(a,c))\n",
    "# print(np.matmul(a,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1d0c51c-165a-4fc4-bc1e-5e489849807f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 1],\n",
       "       [2, 2]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 0],\n",
    "              [0, 1]])\n",
    "\n",
    "b = np.array([[4, 1],\n",
    "              [2, 2]])\n",
    "\n",
    "np.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af0c7e76-07c1-4171-8e57-43e36433a925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([3, 2], dtype=int32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.constant([3.1, 2.2], dtype=tf.float32)\n",
    "tf.cast(x, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "810a49c3-1785-4f3d-ac1f-dc1035730b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21194157 0.5761169  0.21194157]\n",
      "[0.5 0.  0.5]\n"
     ]
    }
   ],
   "source": [
    "inp = np.asarray([1., 2., 1.])\n",
    "layer = tf.keras.layers.Softmax()\n",
    "print(layer(inp).numpy())\n",
    "\n",
    "mask = np.asarray([True, False, True], dtype=bool)\n",
    "print(layer(inp, mask).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6d7af1b-e2a9-4d3a-a1d4-73088f4ebd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 22:51:18.238001: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-09 22:51:18.835846: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-09 22:51:18.835868: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-09 22:51:18.935528: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-09 22:51:20.592843: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-09 22:51:20.593001: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-09 22:51:20.593011: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import matmul, math, cast, float32\n",
    "from tensorflow.keras.layers import Layer\n",
    "from keras.backend import softmax\n",
    "\n",
    "# Implementing the Scaled-Dot Product Attention\n",
    "class DotProductAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, queries, keys, values, d_k, mask=None):\n",
    "        # Scoring the queries against the keys after transposing the latter, and scaling\n",
    "        scores = matmul(queries, keys, transpose_b=True) / math.sqrt(cast(d_k, float32))\n",
    "\n",
    "        # Apply mask to the attention scores\n",
    "        if mask is not None:\n",
    "            scores += -1e9 * mask\n",
    "\n",
    "        # Computing the weights by a softmax operation\n",
    "        weights = softmax(scores)\n",
    "\n",
    "        # Computing the attention by a weighted sum of the value vectors\n",
    "        return matmul(weights, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "809b6f4e-627a-4476-a332-98d6157c0528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "\n",
    "input_seq_length = 5  # Maximum length of the input sequence\n",
    "d_k = 64  # Dimensionality of the linearly projected queries and keys\n",
    "d_v = 64  # Dimensionality of the linearly projected values\n",
    "batch_size = 64  # Batch size from the training process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c906359c-a835-4c48-a652-978b6d297273",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = random.random((batch_size, input_seq_length, d_k))\n",
    "keys = random.random((batch_size, input_seq_length, d_k))\n",
    "values = random.random((batch_size, input_seq_length, d_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee952f1c-feb6-45bb-b701-2bcb62193068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.31373164 0.50834334 0.49225432 ... 0.37507066 0.5073779  0.62816894]\n",
      "  [0.3010763  0.51212627 0.4811234  ... 0.36774445 0.50619113 0.6417378 ]\n",
      "  [0.30915707 0.50104344 0.47912827 ... 0.3604811  0.50952435 0.64546734]\n",
      "  [0.32233158 0.5068095  0.48622227 ... 0.35699242 0.5147048  0.6500409 ]\n",
      "  [0.31363446 0.5011327  0.48151103 ... 0.35594073 0.4995301  0.6393221 ]]\n",
      "\n",
      " [[0.57568467 0.4505603  0.5239681  ... 0.60864043 0.34635928 0.5007811 ]\n",
      "  [0.56853044 0.4515211  0.5351924  ... 0.59896564 0.34720394 0.49745777]\n",
      "  [0.57541496 0.446299   0.5239304  ... 0.6067643  0.35005838 0.49131414]\n",
      "  [0.5688477  0.46354324 0.5282889  ... 0.61735463 0.33002955 0.50611496]\n",
      "  [0.58261573 0.44862354 0.5200349  ... 0.6104262  0.35215896 0.50880325]]\n",
      "\n",
      " [[0.3801898  0.47657895 0.64222425 ... 0.40978184 0.4939991  0.45995554]\n",
      "  [0.38001505 0.48484927 0.6650006  ... 0.4183869  0.49146873 0.46178645]\n",
      "  [0.3644982  0.46663195 0.62561995 ... 0.3844254  0.51748973 0.4600522 ]\n",
      "  [0.38092002 0.4660798  0.6271282  ... 0.40406063 0.48979396 0.46313867]\n",
      "  [0.371292   0.48040238 0.65287715 ... 0.40852574 0.49498188 0.46509686]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.5707157  0.6036711  0.45925745 ... 0.35278785 0.51973134 0.30253968]\n",
      "  [0.57059115 0.6130137  0.44169658 ... 0.32540393 0.50771296 0.27091527]\n",
      "  [0.56729233 0.60081697 0.4213552  ... 0.30279803 0.4888793  0.2649772 ]\n",
      "  [0.56072754 0.59705853 0.43652815 ... 0.32336834 0.49307424 0.27828133]\n",
      "  [0.5648358  0.5975464  0.44123927 ... 0.32528225 0.49859923 0.28016362]]\n",
      "\n",
      " [[0.5673023  0.502487   0.41705644 ... 0.437628   0.4223454  0.7247366 ]\n",
      "  [0.57550216 0.51890427 0.4056426  ... 0.4330318  0.42286235 0.72411233]\n",
      "  [0.576955   0.5217972  0.4010604  ... 0.43421453 0.42112485 0.72710204]\n",
      "  [0.58155525 0.51323843 0.3915224  ... 0.42266285 0.442681   0.7262876 ]\n",
      "  [0.57870877 0.51391023 0.39723045 ... 0.4265935  0.4357018  0.7256316 ]]\n",
      "\n",
      " [[0.6838262  0.46494728 0.47287413 ... 0.5097203  0.40812555 0.38169357]\n",
      "  [0.6833987  0.46394986 0.49747336 ... 0.50945944 0.40800056 0.3762567 ]\n",
      "  [0.6861511  0.46717876 0.47305757 ... 0.5056077  0.4120837  0.37311035]\n",
      "  [0.6837991  0.4673637  0.47374487 ... 0.503464   0.4090066  0.37358755]\n",
      "  [0.66957474 0.45619968 0.52732736 ... 0.5110628  0.39593175 0.38519797]]], shape=(64, 5, 64), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 22:53:16.453615: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-09 22:53:16.454131: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-09 22:53:16.454186: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (3459): /proc/driver/nvidia/version does not exist\n",
      "2023-02-09 22:53:16.455521: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "attention = DotProductAttention()\n",
    "print(attention(queries, keys, values, d_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b941f1b-d8eb-487f-9cd5-18fa16084fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
